{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpar5LziY_-0"
      },
      "source": [
        "#Zadanie 7 (7 pkt)\n",
        "Celem zadania jest zaimplementowanie dwóch wersji naiwnego klasyfikatora Bayesa.\n",
        "* W pierwszej wersji należy dokonać dyskretyzacji danych - przedział wartości każdego atrybutu dzielimy na cztery równe przedziały i każdej ciągłej wartości atrybutu przypisujemy wartość dyskretną wynikająca z przynależności do danego przedziału.\n",
        "* W drugiej wersji wartości likelihood wyliczamy z rozkładów normalnych o średnich i odchyleniach standardowych wynikających z wartości atrybutów.\n",
        "Trening i test należy przeprowadzić dla zbioru Iris, tak jak w przypadku zadania z drzewem klasyfikacyjnym. Proszę przeprowadzić eksperymenty najpierw dla DOKŁADNIE takiego podziału zbioru testowego i treningowego jak umieszczony poniżej. W dalszej części należy przeprowadzić analizę działania klasyfikatorów dla różnych wartości parametrów. Proszę korzystać z przygotowanego szkieletu programu, oczywiście można go modyfikować według potrzeb. Wszelkie elementy szkieletu zostaną wyjaśnione na zajęciach.\n",
        "\n",
        "* Dyskretyzacja danych - **0.5 pkt**\n",
        "* Implementacja funkcji rozkładu normalnego o zadanej średniej i odchyleniu standardowym. - **0.5 pkt**\n",
        "* Implementacja naiwnego klasyfikatora Bayesa dla danych dyskretnych. - **2.0 pkt**\n",
        "* Implementacja naiwnego klasyfikatora Bayesa dla danych ciągłych. - **2.5 pkt**\n",
        "* Przeprowadzenie eksperymentów, wnioski i sposób ich prezentacji. - **1.5 pkt**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XNc-O3npA-J9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train:  [[6.5 3.  5.8 2.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [6.  2.2 5.  1.5]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [5.  3.  1.6 0.2]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [6.7 3.  5.  1.7]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]]\n",
            "x_test:  [[6.3 2.5 4.9 1.5]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.  6.1 2.3]]\n",
            "y_train:  [2 0 0 1 0 0 2 0 2 0 0 0 2 2 0 2 2 0 0 1 1 2 0 0 1 1 0 2 2 2 2 2 1 0 0 2 0\n",
            " 0 1 1 1 1 2 1 2 0 2 1 0 0 2 1 2 2 0 1 1 2 0 2 1 1 0 2 2 0 0 1 1 2 0 0 1 0\n",
            " 1 2 0 2 0 0 1 0 0 1 2 1 1 1 0 0 1 2 0 0 1 1 1 2 1 1 1 2 0 0 1 2 2 2 2 0 1\n",
            " 0 1 1 0 1 2 1 2 2 0 1 0 2 2 1 1 2 2 1 0 1 1 2 2]\n",
            "y_test:  [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from abc import ABC, abstractmethod\n",
        "import math\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)\n",
        "\n",
        "print(\"x_train: \", x_train)\n",
        "print(\"x_test: \", x_test)\n",
        "print(\"y_train: \", y_train)\n",
        "print(\"y_test: \", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BayesSkeleton(ABC):\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.likelihoods = {}\n",
        "\n",
        "    def _calc_priors(self, train_classes):\n",
        "        total_samples = len(train_classes)\n",
        "        for c in np.unique(train_classes):\n",
        "            self.priors[c] = np.sum(train_classes == c) / total_samples\n",
        "\n",
        "    def _calc_likelihoods(self, train_features, train_classes):\n",
        "        for c in self.classes:\n",
        "            self.likelihoods[c] = {}\n",
        "            class_features = train_features[train_classes == c]\n",
        "\n",
        "            for i in range(train_features.shape[1]):\n",
        "                values, counts = np.unique(class_features[:, i], return_counts=True)\n",
        "\n",
        "                for value, count in zip(values, counts):\n",
        "                    # P(X_i = value | Y = c)\n",
        "                    self.likelihoods[c][(i, value)] = count / len(class_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fBh2tfQ44u5k"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes(BayesSkeleton):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.classes: List[int] = None\n",
        "        self.num_classes: int = None\n",
        "\n",
        "        self.bins: List[np.ndarray] = None\n",
        "\n",
        "    def build_classifier(self, train_features, train_classes):\n",
        "        self._compute_bins(train_features)\n",
        "        discretized_features = self._calc_discretized_features(train_features)\n",
        "\n",
        "        self.classes = np.unique(train_classes)\n",
        "        self.num_classes = len(self.classes)\n",
        "\n",
        "        self._calc_priors(train_classes)\n",
        "        self._calc_likelihoods(discretized_features, train_classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def data_discretization(data, bins):\n",
        "        discretized_data = np.digitize(data, bins, right=False) - 1\n",
        "        return discretized_data\n",
        "\n",
        "    def _compute_bins(self, train_features):\n",
        "        self.bins = [\n",
        "            np.linspace(np.min(train_features[:, i]), np.max(train_features[:, i]), 5)\n",
        "            for i in range(train_features.shape[1])\n",
        "        ]\n",
        "\n",
        "    def _calc_discretized_features(self, train_features):\n",
        "        return np.array(\n",
        "            [\n",
        "                self.data_discretization(train_features[:, i], self.bins[i])\n",
        "                for i in range(train_features.shape[1])\n",
        "            ]\n",
        "        ).T\n",
        "\n",
        "    def predict(self, sample):\n",
        "        print(f\"Sample: {sample}\")\n",
        "        discretized_sample = self._discretize_sample(sample)\n",
        "        print(f\"Discretized Sample: {discretized_sample}\")\n",
        "        prediction = self._predict_class(discretized_sample)\n",
        "        print(f\"Prediction: {prediction}\")\n",
        "        return prediction\n",
        "\n",
        "    def _discretize_sample(self, sample):\n",
        "        discretized_sample = np.zeros_like(sample, dtype=int)\n",
        "        for i in range(len(sample)):\n",
        "            discretized_sample[i] = NaiveBayes.data_discretization(sample[i], self.bins[i])\n",
        "\n",
        "        return discretized_sample\n",
        "\n",
        "    def _predict_class(self, discretized_sample):\n",
        "        class_probs = []\n",
        "        for c in self.classes:\n",
        "            # Log(P(Y = c))\n",
        "            class_prob_log = np.log(self.priors[c])\n",
        "\n",
        "            for i, feature in enumerate(discretized_sample):\n",
        "                # Log(P(X_i = value | Y = c))\n",
        "                likelihood = self.likelihoods[c].get((i, feature), 1e-10)\n",
        "                class_prob_log += np.log(likelihood)\n",
        "\n",
        "            class_probs.append(class_prob_log)\n",
        "\n",
        "        return self.classes[np.argmax(class_probs)]\n",
        "\n",
        "class GaussianNaiveBayes(BayesSkeleton):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.classes: List[int] = None\n",
        "        self.num_classes: int = None\n",
        "\n",
        "        self._means: np.ndarray = []\n",
        "        self._std = None\n",
        "\n",
        "    def build_classifier(self, train_features, train_classes):\n",
        "        self.classes = np.unique(train_classes)\n",
        "        self.num_classes = len(self.classes)\n",
        "\n",
        "        self._calc_priors(train_classes)\n",
        "        self._calc_likelihoods(train_features, train_classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def normal_dist(x, mean, std):\n",
        "        if std == 0:\n",
        "            return 1.0 if x == mean else 0.0\n",
        "        exponent = np.exp( -((x - mean) ** 2) / (2 * (std ** 2)))\n",
        "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
        "\n",
        "    def predict(self, sample):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Eksperymenty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9333333333333333\n"
          ]
        }
      ],
      "source": [
        "nbc: NaiveBayes = NaiveBayes()\n",
        "nbc.build_classifier(x_train, y_train)\n",
        "\n",
        "predictions = [nbc.predict(sample) for sample in x_test]\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
